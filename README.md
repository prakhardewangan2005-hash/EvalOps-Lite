# ğŸš€ EvalOps-Lite â€” GenAI Evaluation & Prediction Service

**Production-ready GenAI inference + EvalOps microservice built with FastAPI, designed to demonstrate ML systems thinking, API design, deployment, evaluation workflows, and MLOps fundamentals. Built for extreme shortlisting (top 0.005%), not a toy demo.**

âœ… Live âœ… Containerized âœ… CI/CD-ready âœ… Recruiter-friendly Swagger UI âœ… No local setup required

---

## ğŸ”— Live Demo (Railway â€” No Setup)
Base URL: https://evalops-lite-production.up.railway.app
Swagger UI: https://evalops-lite-production.up.railway.app/docs
OpenAPI Spec: https://evalops-lite-production.up.railway.app/openapi.json

---

## ğŸ§  What This Service Does

EvalOps-Lite is a GenAI inference + evaluation microservice that exposes clean, testable APIs for health monitoring, model registry introspection, and GenAI prediction (text â†’ inference output). This mirrors real-world ML platform services used in production systems at scale.

---

## ğŸ“¦ API Endpoints

GET /health â†’ {"status":"ok"}
GET /models â†’ {"models":["genai-baseline"]}
POST /genai/predict â†’ {"text":"Evaluate this PR for risk and quality"} â†’ {"model":"genai-baseline","input_length":34,"prediction":"processed","confidence":0.92}

---

## ğŸ— Architecture

Client â†’ FastAPI Service â†’ Model Registry â†’ GenAI Baseline (Stateless, production-safe inference)

---

## ğŸ§ª Evaluation & Reliability

Input validation via Pydantic, deterministic baseline inference, structured JSON responses, health/readiness probes, OpenAPI-compliant schemas

---

## ğŸ³ Deployment & Ops

Containerized using Docker (Python 3.11 slim base), hosted on Railway, auto-deploy enabled via GitHub â†’ Railway integration, no terminal required for demo/testing, public networking enabled via Railway-managed domain

---

## ğŸ›  Tech Stack

FastAPI, Pydantic, Docker, GitHub Actions, Railway, Python 3.11

---

## ğŸ“„ License

MIT License

---

## ğŸ¯ Why This Project Matters

This project demonstrates real ML platform engineering skills: API-first ML services, production deployment, CI/CD readiness, evaluation hooks, and recruiter-visible live demos â€” aligned with expectations for MLE / SDE-ML / Platform Engineering roles at top-tier companies.
